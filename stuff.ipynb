{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[5, 4] ['1212', '23', '1234'] None\n[5, 4] ['1212', '23', '1234'] None\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def f():\n",
    "    mb = namedtuple('Minibatch', ['img_attrs', 'person_attrs', 'obj_attrs'])\n",
    "    return mb(img_attrs=[5, 4], person_attrs=['1212', '23', '1234'], obj_attrs=None)\n",
    "\n",
    "a = f()\n",
    "b, c, d = a\n",
    "print(b, c, d)\n",
    "print(a.img_attrs, a.person_attrs, a.obj_attrs)\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# \n",
    "# n = 50\n",
    "# x = np.arange(n + 1)\n",
    "# y = 1 - 1/np.maximum(1, x)\n",
    "# \n",
    "# plt.plot(x, y)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Random stuff\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/HICO/HAKE/Part_State_76.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "part_labels = [l.strip() for l in lines]\n",
    "part_action_pairs = []\n",
    "part_action_dict = {}\n",
    "for l in lines:\n",
    "    pa_pair = [x.strip() for x in l.split(':')]\n",
    "    part, action = pa_pair\n",
    "    part_action_pairs.append(pa_pair)\n",
    "    part_action_dict.setdefault(part, []).append(action)\n",
    "actions = sorted({v for vs in part_action_dict.values() for v in vs})\n",
    "parts = sorted(part_action_dict.keys())\n",
    "\n",
    "hico_parts_train = json.load(open('data/HICO/HAKE/train.json', 'r'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% HAKE\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[ 55 108]\n [ 57  71]\n [ 66  67]\n [ 67  66]\n [ 71  57]\n [ 86  87]\n [ 86  93]\n [ 86  97]\n [ 87  86]\n [ 87  93]\n [ 87  94]\n [ 87 101]\n [ 87 103]\n [ 87 109]\n [ 93  86]\n [ 93  87]\n [ 93  94]\n [ 93 101]\n [ 93 103]\n [ 93 109]\n [ 94  87]\n [ 94  93]\n [ 97  86]\n [101  87]\n [101  93]\n [101 103]\n [101 109]\n [103  87]\n [103  93]\n [103 101]\n [103 109]\n [108  55]\n [109  87]\n [109  93]\n [109 101]\n [109 103]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "embs = pickle.load(open('cache/glove_300_act_norm-avg.pkl', 'rb'))\n",
    "sim = embs @ embs.T\n",
    "out = np.array([7, 17, 21, 25, 38, 50])\n",
    "\n",
    "x, y = np.where(sim - np.eye(sim.shape[0]) >= 0.6)\n",
    "\n",
    "inds = sorted({i for i, n in enumerate(x) if n not in out} &\n",
    "              {i for i, n in enumerate(y) if n not in out})\n",
    "x = x[inds]\n",
    "y = y[inds]\n",
    "print(np.stack([x, y], axis=1))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Embedding similarity\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0., 1.],\n        [2., 3.],\n        [4., 5.]], requires_grad=True)\ntensor([[ 0.,  1.],\n        [ 4.,  9.],\n        [16., 25.]], grad_fn=<PowBackward0>)\ntensor([[ 0.,  2.],\n        [ 4.,  6.],\n        [ 8., 10.]])\n\ntensor([[0., 1.],\n        [2., 3.],\n        [4., 5.]], requires_grad=True)\ntensor([[   0.,    1.],\n        [   4., 2342.],\n        [  16.,   25.]], grad_fn=<CopySlices>)\ntensor([[ 0.,  2.],\n        [ 4.,  0.],\n        [ 8., 10.]])\n\ntensor([[0., 1.],\n        [2., 3.],\n        [4., 5.]], requires_grad=True)\ntensor([[ 0.,  1.],\n        [ 4.,  0.],\n        [16., 25.]], grad_fn=<CopySlices>)\ntensor([[ 0.,  2.],\n        [ 4.,  6.],\n        [ 8., 10.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "x = torch.tensor(torch.from_numpy(np.arange(6).reshape(3, 2)).float(),requires_grad=True)\n",
    "y = x**2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(x) \n",
    "print(y) \n",
    "print(x.grad)\n",
    "\n",
    "print()\n",
    "x = torch.tensor(torch.from_numpy(np.arange(6).reshape(3, 2)).float(),requires_grad=True)\n",
    "y = x**2\n",
    "y[1, 1] = 2342\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(x) \n",
    "print(y) \n",
    "print(x.grad) \n",
    "\n",
    "print()\n",
    "x = torch.tensor(torch.from_numpy(np.arange(6).reshape(3, 2)).float(),requires_grad=True)\n",
    "y = x**2\n",
    "y[1, 1] -= 9\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(x) \n",
    "print(y) \n",
    "print(x.grad) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Pytorch 0 loss\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor(1, dtype=torch.uint8)\nFalse True True\ntensor([[0., 1.],\n        [2., 3.],\n        [4., 5.],\n        [6., 7.],\n        [8., 9.]], requires_grad=True)\ntensor([[0., 1.],\n        [2., 3.],\n        [4., 5.],\n        [6., 7.],\n        [8., 9.]], grad_fn=<TakeBackward>)\ntensor([[ 0.,  1.],\n        [ 4.,  9.],\n        [16., 25.],\n        [36., 49.],\n        [64., 81.]], grad_fn=<PowBackward0>)\nNone\nNone\nNone\nNone\ntensor([[ 0.,  0.],\n        [ 4.,  6.],\n        [ 8., 10.],\n        [ 0.,  0.],\n        [ 0.,  0.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "n = 5\n",
    "x0 = torch.tensor(torch.from_numpy(np.arange(n*2).reshape(n, 2)).float(),requires_grad=True)\n",
    "a_inds = torch.from_numpy(np.array([0, 3, 4]))\n",
    "b_inds = torch.from_numpy(np.array([i for i in range(n) if i not in a_inds]))\n",
    "a = x0[a_inds, :].detach()\n",
    "b = x0[b_inds, :]\n",
    "x = torch.cat([a, b], dim=0)[torch.sort(torch.cat([a_inds, b_inds]))[1]]\n",
    "print((x0 == x).all())\n",
    "y = x**2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(a.requires_grad, b.requires_grad, x.requires_grad)\n",
    "print(x0) \n",
    "print(x) \n",
    "print(y) \n",
    "print(y.grad)\n",
    "print(x.grad)\n",
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(x0.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Pytorch grad of concatenation of grad-requiring tensor with detached one\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% LIS\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n = 100\n",
    "x = np.arange(n + 1) / n\n",
    "\n",
    "w, k = 96, 10\n",
    "T = 1 + np.exp(k - w).item()\n",
    "y = T / (1 + np.exp(-(w * x - k)))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.gca().set_xticks(np.arange(11) / 10)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['tench', 'Tinca tinca']\n['goldfish', 'Carassius auratus']\n['ear', 'spike', 'capitulum']\n['toilet tissue', 'toilet paper', 'bathroom tissue']\n",
      "{0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 12: 'stop sign', 13: 'parking meter', 14: 'bench', 15: 'bird', 16: 'cat', 17: 'dog', 18: 'horse', 19: 'sheep', 20: 'cow', 21: 'elephant', 22: 'bear', 23: 'zebra', 24: 'giraffe', 25: 'backpack', 26: 'umbrella', 27: 'handbag', 28: 'tie', 29: 'suitcase', 30: 'frisbee', 31: 'skis', 32: 'snowboard', 33: 'sports ball', 34: 'kite', 35: 'baseball bat', 36: 'baseball glove', 37: 'skateboard', 38: 'surfboard', 39: 'tennis racket', 40: 'bottle', 41: 'wine glass', 42: 'cup', 43: 'fork', 44: 'knife', 45: 'spoon', 46: 'bowl', 47: 'banana', 48: 'apple', 49: 'sandwich', 50: 'orange', 51: 'broccoli', 52: 'carrot', 53: 'hot dog', 54: 'pizza', 55: 'donut', 56: 'cake', 57: 'chair', 58: 'couch', 59: 'potted plant', 60: 'bed', 61: 'dining table', 62: 'toilet', 63: 'tv', 64: 'laptop', 65: 'mouse', 66: 'remote', 67: 'keyboard', 68: 'cell phone', 69: 'microwave', 70: 'oven', 71: 'toaster', 72: 'sink', 73: 'refrigerator', 74: 'book', 75: 'clock', 76: 'vase', 77: 'scissors', 78: 'teddy bear', 79: 'hair drier', 80: 'toothbrush'}\n22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open('imagenet1000classes.txt', 'r') as f:\n",
    "    inet_categories = [' '.join(l.strip('{}, \\n').split()[1:]).strip(\"'\").split(', ') \n",
    "               for l in f.readlines()]\n",
    "print(inet_categories[0])\n",
    "print(inet_categories[1])\n",
    "print(inet_categories[-2])\n",
    "print(inet_categories[-1])\n",
    "\n",
    "from lib.detection.wrappers import COCO_CLASSES\n",
    "print(COCO_CLASSES)\n",
    "\n",
    "common = set(COCO_CLASSES.values()) & {c for cat in inet_categories for c in cat}\n",
    "print(len(common))   \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imagenet vs COCO classes\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "to_filter = [19, 25, 117, 144, 151, 152, 154, 163, 167, \n",
    "             190, 245, 258, 307, 326, 347, 366, 400, \n",
    "             433, 434, 466, 471, 476, 479, 523, 598]\n",
    "keep = set(range(600)) - set(to_filter)\n",
    "d = {'train': {'inter': np.array(sorted(keep))\n",
    "               }\n",
    "     }\n",
    "with open('zero-shot_inds/seen_inds_2.pkl.push', 'wb') as f:\n",
    "    pickle.dump(d, f)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Seen file #2 (inter only)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from lib.dataset.hico.hico import Hico\n",
    "\n",
    "hico = Hico()\n",
    "num_seen_obj = 40 \n",
    "num_seen_act = 59 \n",
    "\n",
    "with open('imagenet1000classes.txt', 'r') as f:\n",
    "    inet_categories = [' '.join(l.strip('{}, \\n').split()[1:]).strip(\"'\").split(', ') \n",
    "                       for l in f.readlines()]\n",
    "    inet_classes = {c for cat in inet_categories for c in cat}\n",
    "\n",
    "hico_objects = [obj.replace('_', ' ') for obj in hico.objects]\n",
    "common_str = set(hico_objects) & inet_classes\n",
    "common = {i for i, n in enumerate(hico_objects) if n in common_str}\n",
    "print(len(common))\n",
    "hico_only = set(range(hico.num_object_classes)) - common - {hico.human_class}\n",
    "\n",
    "all_num_inters = []\n",
    "all_data = []\n",
    "for i in range(10**5):\n",
    "    np.random.seed(i)\n",
    "    seen_obj = np.random.choice(np.array(list(hico_only)), \n",
    "                                size=num_seen_obj - len(common) - 1, replace=False)\n",
    "    seen_obj = np.sort(np.concatenate([seen_obj, np.array([hico.human_class]), np.array(list(common))]))\n",
    "    assert hico.human_class in seen_obj\n",
    "    \n",
    "    seen_act = np.random.choice(np.arange(1, hico.num_predicates), size=num_seen_act - 1, replace=False)\n",
    "    seen_act = np.sort(np.concatenate([np.array([0]), seen_act]))\n",
    "    \n",
    "    num_inters = (hico.op_pair_to_interaction[seen_obj, :][:, seen_act] >= 0).sum()\n",
    "    all_num_inters.append(num_inters)\n",
    "    all_data.append([seen_obj, seen_act])\n",
    "\n",
    "m = np.argmax(np.array(all_num_inters))\n",
    "num_inters = all_num_inters[m]\n",
    "seen_obj, seen_act = all_data[m]\n",
    "u_seen_obj = np.unique(seen_obj)\n",
    "u_seen_act = np.unique(seen_act)\n",
    "assert seen_obj.size == num_seen_obj and seen_act.size == num_seen_act\n",
    "assert u_seen_obj.size == num_seen_obj and u_seen_act.size == num_seen_act\n",
    "d = {'train': {'obj': seen_obj, 'pred':seen_act}}\n",
    "with open('zero-shot_inds/seen_inds_3.pkl.push', 'wb') as f:\n",
    "    pickle.dump(d, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Seen file #3 (obj/pred)\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from lib.dataset.hico.hico import Hico\n",
    "\n",
    "hico = Hico()\n",
    "num_seen_obj = 40 \n",
    "num_seen_act = 59 \n",
    "\n",
    "with open('imagenet1000classes.txt', 'r') as f:\n",
    "    inet_categories = [' '.join(l.strip('{}, \\n').split()[1:]).strip(\"'\").split(', ') \n",
    "                       for l in f.readlines()]\n",
    "    inet_classes = {c for cat in inet_categories for c in cat}\n",
    "\n",
    "hico_objects = [obj.replace('_', ' ') for obj in hico.objects]\n",
    "common_str = set(hico_objects) & inet_classes\n",
    "common = {i for i, n in enumerate(hico_objects) if n in common_str}\n",
    "print(len(common))\n",
    "hico_only = set(range(hico.num_object_classes)) - common - {hico.human_class}\n",
    "\n",
    "np.random.seed(42)\n",
    "seen_obj = np.random.choice(np.array(list(hico_only)), \n",
    "                            size=num_seen_obj - len(common) - 1, replace=False)\n",
    "seen_obj = np.sort(np.concatenate([seen_obj, np.array([hico.human_class]), np.array(list(common))]))\n",
    "assert hico.human_class in seen_obj\n",
    "\n",
    "seen_act = np.random.choice(np.arange(1, hico.num_predicates), size=num_seen_act - 1, replace=False)\n",
    "seen_act = np.sort(np.concatenate([np.array([0]), seen_act]))\n",
    "\n",
    "u_seen_obj = np.unique(seen_obj)\n",
    "u_seen_act = np.unique(seen_act)\n",
    "assert seen_obj.size == num_seen_obj and seen_act.size == num_seen_act\n",
    "assert u_seen_obj.size == num_seen_obj and u_seen_act.size == num_seen_act\n",
    "d = {'train': {'obj': seen_obj, 'pred':seen_act}}\n",
    "with open('zero-shot_inds/seen_inds_4.pkl.push', 'wb') as f:\n",
    "    pickle.dump(d, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Seen file #4 (obj/pred)\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from lib.dataset.hico.hico import Hico\n",
    "\n",
    "hico = Hico()\n",
    "num_seen_obj = 40 \n",
    "num_seen_act = 59 \n",
    "\n",
    "with open('imagenet1000classes.txt', 'r') as f:\n",
    "    inet_categories = [' '.join(l.strip('{}, \\n').split()[1:]).strip(\"'\").split(', ') \n",
    "                       for l in f.readlines()]\n",
    "    inet_classes = {c for cat in inet_categories for c in cat}\n",
    "\n",
    "hico_objects = [obj.replace('_', ' ') for obj in hico.objects]\n",
    "common_str = set(hico_objects) & inet_classes\n",
    "common = {i for i, n in enumerate(hico_objects) if n in common_str}\n",
    "print(len(common))\n",
    "hico_only = set(range(hico.num_object_classes)) - common - {hico.human_class}\n",
    "\n",
    "all_num_inters = []\n",
    "all_data = []\n",
    "for i in range(10**5):\n",
    "    np.random.seed(i)\n",
    "    seen_obj = np.random.choice(np.array(list(hico_only)), \n",
    "                                size=num_seen_obj - len(common) - 1, replace=False)\n",
    "    seen_obj = np.sort(np.concatenate([seen_obj, np.array([hico.human_class]), np.array(list(common))]))\n",
    "    assert hico.human_class in seen_obj\n",
    "    \n",
    "    seen_act = np.random.choice(np.arange(1, hico.num_predicates), size=num_seen_act - 1, replace=False)\n",
    "    seen_act = np.sort(np.concatenate([np.array([0]), seen_act]))\n",
    "    \n",
    "    num_inters = (hico.op_pair_to_interaction[seen_obj, :][:, seen_act] >= 0).sum()\n",
    "    all_num_inters.append(num_inters)\n",
    "    all_data.append([seen_obj, seen_act])\n",
    "\n",
    "m = np.argmin(np.array(all_num_inters))\n",
    "num_inters = all_num_inters[m]\n",
    "seen_obj, seen_act = all_data[m]\n",
    "u_seen_obj = np.unique(seen_obj)\n",
    "u_seen_act = np.unique(seen_act)\n",
    "assert seen_obj.size == num_seen_obj and seen_act.size == num_seen_act\n",
    "assert u_seen_obj.size == num_seen_obj and u_seen_act.size == num_seen_act\n",
    "d = {'train': {'obj': seen_obj, 'pred':seen_act}}\n",
    "with open('zero-shot_inds/seen_inds_5.pkl.push', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Seen file #5 (obj/pred)\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "49 54 205\n80 520 205 156\n232.828125\n",
      "198.9375\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pickle\n",
    "from lib.dataset.hico import Hico\n",
    "from lib.dataset.utils import Splits\n",
    "import numpy as np\n",
    "\n",
    "fnum = 0\n",
    "d = pickle.load(open(f'zero-shot_inds/seen_inds_{fnum}.pkl.push', 'rb'))\n",
    "pinds = d['train']['act']\n",
    "oinds = d['train']['obj']\n",
    "\n",
    "hd = Hico()\n",
    "print(len(oinds), len(pinds), \n",
    "      (hd.op_pair_to_interaction[oinds, :][:, pinds] >= 0).sum())\n",
    "\n",
    "null_interactions = np.array(sorted(set(\n",
    "    np.unique((hd.op_pair_to_interaction[:, 0])).tolist()) - {-1}))\n",
    "non_null_interactions = np.array(sorted(set(\n",
    "    np.unique((hd.op_pair_to_interaction[:, 1:])).tolist()) - {-1}))\n",
    "tr_interactions = np.array(sorted(set(\n",
    "    np.unique((hd.op_pair_to_interaction[oinds, :][:, pinds])).tolist()) - {-1}))\n",
    "tr_non_null_interactions = np.intersect1d(non_null_interactions, tr_interactions)\n",
    "\n",
    "print(null_interactions.size, non_null_interactions.size, tr_interactions.size, tr_non_null_interactions.size)\n",
    "\n",
    "print(np.sum(np.any(hd.split_annotations[Splits.TRAIN][:, tr_interactions], axis=1)) / 64)\n",
    "print(np.sum(np.any(hd.split_annotations[Splits.TRAIN][:, tr_non_null_interactions], axis=1)) / 64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Number seen (obj/pred)\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "A young woman is seen standing in a room and leads into her dancing.\n[1.86528073 1.86528073]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import json\n",
    "d = json.load(open('data/VideoCaptions/train.json', 'r'))\n",
    "captions = [s for v in d.values() for s in v['sentences']]\n",
    "print(captions[0])\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% VideoCaptions dataset captions\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10799\n4251\n15050\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open('data/VG/Kato/VG_train_1A2B.csv', 'r') as f:\n",
    "    tr_fns = {l.strip().split(',')[0] for l in f.readlines() if l.strip()}\n",
    "\n",
    "with open('data/VG/Kato/VG_test.csv', 'r') as f:\n",
    "    te_fns = {l.strip().split(',')[0] for l in f.readlines() if l.strip()}\n",
    "\n",
    "print(len(tr_fns))\n",
    "print(len(te_fns))\n",
    "print(len(tr_fns | te_fns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}